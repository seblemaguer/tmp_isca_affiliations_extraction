{"time": "2026-02-01 15:05:42,321", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['nikola ljubesi\u0107', 'ivan porupski', 'peter rupnik']\n\t- header: ['Identifying Primary Stress Across Related Languages and Dialects with', 'Transformer-based Speech Encoder Models', 'Nikola Ljubesic1,2,3, Ivan Porupski1, Peter Rupnik1', '1Department of Knowledge Technologies, Jo\u02c7zef Stefan Institute, Slovenia', '2Faculty of Computer and Information Science, University of Ljubljana, Slovenia', '3Institute of Contemporary History, Ljubljana, Slovenia']", "paper_id": "ljubesic25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:42,437", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['ankita ankita', 'shambhavi shambhavi', 'syed shahnawazuddin']\n\t- header: [\"On Enhancing the Performance of Children's ASR Task in Limited Data\", 'Scenario', 'Ankita 1, Shambhavi 2, Syed Shahnawazuddin1', '1Department of ECE, NIT Patna, India', '2Computer Science Department, IIT Patna, India']", "paper_id": "ankita25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:42,692", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['dan oneata', 'leanne nortje', 'yevgen matusevych', 'herman kamper']\n\t- header: ['The mutual exclusivity bias of bilingual visually grounded speech models', 'Dan Oneat, \u02d8a1, Leanne Nortje2, Yevgen Matusevych3, Herman Kamper2', '1SpeeD Lab, Politehnica Bucharest, Romania', '2Electrical and Electronic Engineering, Stellenbosch University, South Africa', '3CLCG, University of Groningen, the Netherlands']", "paper_id": "oneata25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:43,032", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['dominika c woszczyk', 'ranya aloufi', 'soteris demetriou']\n\t- header: ['ClaritySpeech: Dementia Obfuscation in Speech', 'Dominika Woszczyk1, Ranya Aloufi1,2, Soteris Demetriou1', '1Imperial College London, UK', '2Taibah University, Saudi Arabia']", "paper_id": "woszczyk25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:43,188", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['magdalena gol\u0119biowska', 'piotr syga']\n\t- header: ['EmoSpeechAuth: Emotion-Aware Speaker Verification', 'Magdalena Gol\u02dbebiowska, Piotr Syga', 'Department of Artificial Intelligence, Wroclaw University of Science and Technology, Poland']", "paper_id": "goebiowska25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:43,650", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['jia-xin chen', 'yi-ming wang', 'ziyu zhang', 'jiayang han', 'yin-long liu', 'rui feng', 'xiuyuan liang', 'zhen-hua ling', 'jia-hong yuan']\n\t- header: ['Decoding Speaker-Normalized Pitch from EEG for Mandarin Perception', 'Jiaxin Chen1,2, Yiming Wang1,2, Ziyu Zhang2, Jiayang Han2, Yin-Long Liu1,2, Rui Feng1,2, Xiuyuan', 'Liang2, Zhen-Hua Ling1,2, Jiahong Yuan1,2\u2217', '1National Engineering Research Center of Speech and Language Information Processing, University', 'of Science and Technology of China, Hefei, P. R. China', '2Interdisciplinary Research Center for Linguistic Sciences, University of Science and Technology of', 'China, Hefei, P. R. China']", "paper_id": "chen25e_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:43,845", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['christina t\u00e5nnander', 'david house', 'jonas beskow', 'jens edlund']\n\t- header: ['Intrasentential English in Swedish TTS: perceived English-accentedness', 'Christina T\u02daannander1,2, David House1, Jonas Beskow1, Jens Edlund1', '1Speech, Music and Hearing, KTH Royal Institute of Technology, Sweden', '2Swedish Agency for Accessible Media, MTM, Sweden']", "paper_id": "tannander25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:43,985", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['\u015feymanur akti', 'tuan-nam nguyen', 'alexander waibel']\n\t- header: ['Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive', 'Voice Conversion', 'Seymanur Akti1, Tuan Nam Nguyen1, Alexander Waibel1,2', '1Interactive Systems Lab, Karlsruhe Institute for Technology, Germany', '2Carnegie Mellon University, USA']", "paper_id": "akti25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:44,131", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: [' mansi', 'anastasios lepipas', 'dominika c woszczyk', 'yiying guan', 'soteris demetriou']\n\t- header: ['Understanding Dementia Speech Alignment with Diffusion-Based Image', 'Generation', 'Mansi \u2217, Anastasios Lepipas \u2217, Dominika Woszczyk, Yiying Guan, Soteris Demetriou', 'Imperial College London, UK']", "paper_id": "mansi25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:44,561", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['griffin smith', 'dianna yee', 'jennifer king chen', 'leah findlater']\n\t- header: ['Prompting Whisper for Improved Verbatim Transcription and End-to-end', 'Miscue Detection', 'Griffin Dietz Smith1\u2217, Dianna Yee1\u2217, Jennifer King Chen1, Leah Findlater1', '1Apple']", "paper_id": "smith25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:44,976", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['jinxin ji', 'yiying hu', 'xiaohu yang', 'gang peng']\n\t- header: ['Acoustic Features of Mandarin Tone Production in Noise:  ', 'A Comparison Between Chinese Native Speakers and Korean L2 Learners ', 'Jinxin Ji 1,2; Yiying Hu 1; Xiaohu Yang 2*; Gang Peng 1* ', '1 Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong SAR ', '2 Department of English, Tongji University, China ']", "paper_id": "ji25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:45,075", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['kenichi fujita', 'shota horiguchi', 'yusuke ijima']\n\t- header: ['Voice Impression Control in Zero-Shot TTS', 'Keinichi Fujita, Shota Horiguchi, Yusuke Ijima', 'NTT, Inc., Japan']", "paper_id": "fujita25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:45,100", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['peidong wei', 'shiyu miao', 'lin li']\n\t- header: ['Abstract', 'Deep neural networks have been applied to audio spectro-', 'grams for respiratory sound classification, but it remains chal-', 'lenging to achieve satisfactory performance due to the scarcity', 'of available data. Moreover, domain mismatch may be intro-', 'duced into the trained models as a result of the respiratory sound', 'samples being collected from various electronic stethoscopes,', 'patient demographics, and recording environments. To tackle', 'this issue, we proposed a modified Masked Autoencoder (MAE)', 'model, named Disentangling Dual-Encoder MAE (DDE-MAE)', 'for respiratory sound classification. Two independent encoders', 'were designed to capture disease-related and disease-irrelevant', 'information separately, achieving feature disentanglement to re-', 'duce the domain mismatch. Our method achieves a competitive', 'performance on the ICBHI dataset.', 'Index Terms: respiratory sound classification, ICBHI, feature', 'disentanglement, masked autoencoder', '1. Introduction', 'Respiratory sound classification is an essential task in the early', 'detection and diagnosis of respiratory diseases. Accurate clas-', 'sification can assist healthcare professionals in identifying con-', 'ditions such as asthma, bronchitis, and pneumonia from respi-', 'ratory sounds[1]. However, several challenges arise due to the', 'variability in recording conditions.', 'Respiratory sound data are collected from different patients', 'using various stethoscopes in diverse environments. This vari-', 'ability introduces significant domain mismatch problems[2],', 'making it difficult for models to generalize across different', 'datasets[3][4]. Furthermore, in real-world scenarios, respira-', 'tory sound data are often from unseen domains, and obtaining', 'information about these specific domains is frequently imprac-', 'tical. This makes the challenge of domain adaptation even more', 'difficult to address.', 'Recently, numerous studies have attempted various meth-', 'ods to improve model performance. For instance, Audio Spec-', 'trogram Transformer with Patch-Mix and Contrastive Learning', '(AST + Patch-Mix CL)[5] employs a mix-based data augmenta-', 'tion method and establishes a corresponding contrastive learn-', 'ing approach to address the issue of data scarcity. The Multi-', 'View Spectrogram Transformer (MVST)[6] adopts an ensem-', 'ble approach that combines multiple models trained on different', 'views of the data to achieve performance enhancement. Bridg-', 'ing Text and Sound Modalities (BTS)[7] is a multimodal ap-', 'proach, integrating textual information, such as patient demo-', 'graphics (age, gender) and stethoscope recording conditions,', 'with audio data. Furthermore, some researchers have attempted', 'to address domain adaptation by utilizing the classification la-', 'bels of the stethoscope used during recording and incorporat-', 'ing these labels into domain adversarial[8] training methods[9].', 'Although it is helpful in improving performance, the approach', 'still heavily depends on the availability of labeled information,', 'which is often limited. For instance, the ICBHI dataset [10]', 'includes only four types of stethoscopes, and relying on these', \"limited labels restricts the model's ability to generalize to new,\", 'unseen environments or stethoscope types.', 'In this paper, we propose a novel self-supervised approach', 'that does not require label information of domain (e.g., types of', 'stethoscopes). The overall structure, the Disentangling Dual-', 'Encoder Masked Autoencoder[11] (DDE-MAE) is shown in', 'Fig. 1, which leverages the power of self-supervised learning', 'to disentangle disease-related features from disease-irrelevant', 'features. Hence, our model can achieve effective domain adap-', 'tation without the need for extensive domain labels.', 'Our DDE-MAE model employs two independent encoders.', 'The disease-related encoder captures features directly related', 'to respiratory diseases.', 'The disease-irrelevant encoder cap-', 'tures background and non-disease-related features by process-', 'ing both the original spectrogram and a time-shuffled version', 'of the spectrogram, using a Siamese loss to enforce feature', 'invariance to temporal changes. Additionally, To ensure that', 'the embeddings captured by the two encoders are independent,', 'we employ the variational Contrastive Log-ratio Upper Bound', '(vCLUB) algorithm [12] to estimate and minimize the mutual', 'information between the embeddings from the disease-related', 'encoder and the disease-irrelevant encoder. Our contributions', 'can be summarized as follows:', '\u2022 We introduce a dual-encoder architecture for respiratory', 'sound classification that disentangles disease-related and', 'disease-irrelevant information.', '\u2022 We propose a self-supervised learning approach that ad-', 'dresses domain adaptation without relying on domain infor-', 'mation.', '\u2022 We demonstrate the effectiveness of our method on the', 'ICBHI dataset, achieving a competitive performance and', 'highlighting its potential for real-world applications.', '2. Methodology', '2.1. Overview of Proposed DDE-MAE', 'Our proposed model, Disentangling Dual-Encoder MAE (DDE-', 'MAE), leverages the principles of the Masked Autoencoder', '(MAE) architecture to address the domain adaptation chal-', 'lenges in respiratory sound classification. The MAE architec-', 'ture typically consists of an encoder-decoder structure. The en-', 'coder processes the input spectrograms by masking a portion', 'of the input and learning to represent the unmasked parts effi-', 'ciently. The decoder reconstructs the masked parts from the en-', 'Disentangling', 'Dual-Encoder', 'Masked', 'Autoencoder', 'for', 'Respiratory', 'Sound', 'Classification', 'Peidong', 'Wei,', 'Shiyu', 'Miao,', 'Lin', 'Li*', ' School', 'of', 'Electronic', 'Science', 'and', 'Engineering,', 'Xiamen', 'University,', 'China', 'Interspeech 2025', '17-21 August 2025, Rotterdam, The Netherlands', '1013', '10.21437/Interspeech.2025-1209']", "paper_id": "wei25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:45,316", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['dashanka da silva', 'siqi cai', 'saurav pahuja', 'tanja schultz', 'haizhou li']\n\t- header: ['NeuroSpex+: Dual-Task Training of Neuro-Guided Speaker Extraction with', 'Speech Envelope and Waveform', 'Dashanka De Silva1, Siqi Cai\u2217,3, Saurav Pahuja1,Tanja Schultz2, Haizhou Li1,4', '1Machine Listening Lab (MLL), University of Bremen, Germany', '2Cognitive Systems Lab (CSL), University of Bremen, Germany', '3Department of ECE, National University of Singapore, Singapore', '4School of Data Science, The Chinese University of Hong Kong, Shenzhen,China']", "paper_id": "dasilva25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:45,388", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['mohammed al-radhi', 'geza nemeth', 'branislav gerazov']\n\t- header: ['MiSTR: Multi-Modal iEEG-to-Speech Synthesis with Transformer-Based ', 'Prosody Prediction and Neural Phase Reconstruction ', 'Mohammed Salah Al-Radhi1, Geza Nemeth1, Branislav Gerazov2 ', '1Department of Telecommunications and Artificial Intelligence, Budapest University of Technology ', 'and Economics, Budapest, Hungary ', '2Faculty of Electrical Engineering and Information Technologies, University of Ss. Cyril and ', 'Methodius, Skopje, RN Macedonia ']", "paper_id": "alradhi25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:45,662", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['ahmed attia', 'dorottya demszky', 'jing liu', 'carol espy-wilson']\n\t- header: ['From Weak Labels to Strong Results: Utilizing 5,000 Hours of Noisy', 'Classroom Transcripts with Minimal Accurate Data', 'Ahmed Adel Attia1, Dorottya Demszky2, Jing Liu3, Carol Espy-Wilson1', '1Electrical and Computer Engineering, University of Maryland,', '2Graduate School of Education, Stanford University,', '3College of Education, University of Maryland,']", "paper_id": "attia25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:46,016", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['hawau toyin', 'rufael marew', 'humaid alblooshi', 'samar m. magdy', 'hanan aldarmaki']\n\t- header: ['ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis', 'Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki', 'Mohamed Bin Zayed University of Artificial Intelligence, UAE']", "paper_id": "toyin25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:46,355", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['enes ugan', 'ngoc-quan pham', 'alexander waibel']\n\t- header: ['Weight Factorization and Centralization for Continual Learning', 'in Speech Recognition', 'Enes Yavuz Ugan1,\u2217, Ngoc-Quan Pham2,\u2217, Alexander Waibel1,2', '1Interactive Systems Lab, Karlsruhe Institut of Technology (KIT), Germany', '2InterACT, Carnegie Mellon University (CMU), USA']", "paper_id": "ugan25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:46,747", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['mingxi lu', 'ran tao', 'yujia tian']\n\t- header: ['Talker Normalization in Chinese Bilinguals: A Comparative Study ', 'LU Mingxi1, TIAN Yujia1, TAO Ran1 ', '1Research Centre for Language, Cognition, and Neuroscience, Department of Chinese and Bilingual ', 'Studies, The Hong Kong Polytechnic University, Hong Kong, China ']", "paper_id": "lu25g_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:46,849", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['cathal \u00f3 faolain', 'andrew hines']\n\t- header: ['Attention Models and Auditory Transduction Features for Noise Robustness', 'Cathal \u00b4O Faol\u00b4ain1, Andrew Hines1', '1School of Computer Science, University College Dublin, Ireland']", "paper_id": "ofaolain25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:46,857", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['truong do', 'minh-phuong nguyen', 'le -minh nguyen']\n\t- header: ['PruneSLU: Efficient On-device Spoken Language Understanding through', 'Vocabulary and Structural Pruning', 'Dinh-Truong Do, Minh-Phuong Nguyen, Le-Minh Nguyen', 'Japan Advanced Institute of Science and Technology, Japan']", "paper_id": "do25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:47,251", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['nagarathna ravi', 'thishyan raj t', 'ravi teja chaganti', 'vipul arora']\n\t- header: ['ASR Confidence Estimation using True Class Lexical Similarity Score', 'Nagarathna R1, Thishyan Raj T2, Ravi Teja Chaganti2, Vipul Arora2', '1Big Data Research and Supercomputing Division; AcSIR, CSIR-4PI, India', '2Department of Electrical Engineering, IIT Kanpur, India']", "paper_id": "ravi25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:47,322", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['bartlomiej zgorzy\u0144ski', 'juliusz wojtowicz-kruk', 'piotr masztalski', 'wladyslaw \u015bredniawa']\n\t- header: ['Multi-task learning for speech emotion recognition in naturalistic conditions', 'Bartlomiej Zgorzy\u00b4nski1, Juliusz Wojtowicz-Kruk1, Piotr Masztalski1,2, Wladyslaw \u00b4Sredniawa1', '1Samsung R&D Institute Poland,', '2AGH University of Krakow, Poland']", "paper_id": "zgorzynski25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:47,653", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['szymon szmajdzi\u0144ski', 'juliusz wojtowicz-kruk', 'ivan ryzhankow', '\u0142ukasz \u0142azarski', 'jakub \u017cak', 'wladyslaw \u015bredniawa']\n\t- header: ['Significance of Time-Frequency preprocessing for automatic Ultrasonic', 'Vocalization classification in Autism Spectrum Disorder model detection', 'Szymon Szmajdzi\u00b4nski1, Juliusz Wojtowicz-Kruk1, Ivan Ryzhankow1, \u0141ukasz \u0141azarski1, Jakub \u02d9Zak1,', 'Wladyslaw \u00b4Sredniawa1', '1Samsung R&D Institute Poland,']", "paper_id": "szmajdzinski25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:47,780", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['emma cathrine liisborg leschly', 'oliver roesler', 'michael neumann', 'jackson liscombe', 'abhishek hosamath', 'lakshmi arbatti', 'line h. clemmensen', 'melanie ganz', 'vikram ramanarayanan']\n\t- header: ['An Exploration of Interpretable Deep Learning Models for the Assessment of', 'Mild Cognitive Impairment', 'Emma C. L. Leschly1,3, Oliver Roesler1, Michael Neumann1, Jackson Liscombe1, Abhishek', 'Hosamath1, Lakshmi Arbatti1, Line H. Clemmensen5, Melanie Ganz3,4, Vikram Ramanarayanan1,2', '1Modality.AI, Inc., San Francisco, CA, USA. 2University of California, San Francisco, San', 'Francisco, CA, USA. 3Department of Computer Science, University of Copenhagen, Copenhagen,', 'Denmark. 4Neurobiology Research Unit, Copenhagen University Hospital, Copenhagen, Denmark.', '5Department of Mathematical Sciences, University of Copenhagen, Copenhagen, Denmark']", "paper_id": "leschly25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:48,022", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['zheng xin yong', 'vineel pratap', 'michael auli', 'jean maillard']\n\t- header: ['Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent', 'Robustness in Low-Resource ASR', 'Zheng-Xin Yong1,\u2217, Vineel Pratap2, Michael Auli\u2020, Jean Maillard2', '1Department of Computer Science, Brown University, United States', '2Meta FAIR, United States']", "paper_id": "yong25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:48,877", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['dirk hoffner', 'simon weihe', 'thomas brand', 'bernd t. meyer']\n\t- header: ['Hearing deficits of transformer-based multilingual ASR for anechoic and', 'spatial signals', 'Dirk Eike Hoffner1,3, Simon Weihe2,3, Thomas Brand2,3, Bernd T. Meyer1,3', '1Communications Acoustics, Carl von Ossietzky Universit\u00a8at Oldenburg, Germany', '2Medizinische Physik, Carl von Ossietzky Universit\u00a8at Oldenburg, Germany', '3Cluster of Excellence Hearing4all, Carl von Ossietzky Universit\u00a8at Oldenburg, Germany']", "paper_id": "hoffner25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:49,081", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['teodora vukovi\u0107', 'jeremy zehr', 'jonathan schaber', 'igor mustac', 'nikolina rajovi\u0107', 'daniel mcdonald', 'johannes graen', 'noah bubenhofer']\n\t- header: ['LiRI Corpus Platform: Demonstration of a Web-Based Infrastructure for', 'Multimodal Corpus Analysis', 'Teodora Vukovic1, Jeremy Zehr1, Jonathan Schaber1, Igor Mustac1, Nikolina Rajovic1, Daniel', 'McDonald1, Johannes Gra\u00a8en1, Noah Bubenhofer1', '1Linguistic Research Infrastructure, University of Zurich, Switerland']", "paper_id": "vukovic25_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:05:49,130", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "moore25_interspeech doesn't have a PDF", "paper_id": "moore25_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:05:49,130", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "waibel25_interspeech doesn't have a PDF", "paper_id": "waibel25_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:05:49,130", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "espywilson25_interspeech doesn't have a PDF", "paper_id": "espywilson25_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:05:49,130", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "holler25_interspeech doesn't have a PDF", "paper_id": "holler25_interspeech", "error_step": "pdf_loading"}
