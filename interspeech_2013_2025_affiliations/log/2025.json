{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['dan oneata', 'leanne nortje', 'yevgen matusevych', 'herman kamper']\n\t- header: ['The mutual exclusivity bias of bilingual visually grounded speech models', 'Dan Oneat, \u02d8a1, Leanne Nortje2, Yevgen Matusevych3, Herman Kamper2', '1SpeeD Lab, Politehnica Bucharest, Romania', '2Electrical and Electronic Engineering, Stellenbosch University, South Africa', '3CLCG, University of Groningen, the Netherlands']", "paper_id": "oneata25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['dominika c woszczyk', 'ranya aloufi', 'soteris demetriou']\n\t- header: ['ClaritySpeech: Dementia Obfuscation in Speech', 'Dominika Woszczyk1, Ranya Aloufi1,2, Soteris Demetriou1', '1Imperial College London, UK', '2Taibah University, Saudi Arabia']", "paper_id": "woszczyk25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['magdalena gol\u0119biowska', 'piotr syga']\n\t- header: ['EmoSpeechAuth: Emotion-Aware Speaker Verification', 'Magdalena Gol\u02dbebiowska, Piotr Syga', 'Department of Artificial Intelligence, Wroclaw University of Science and Technology, Poland']", "paper_id": "goebiowska25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['jia-xin chen', 'yi-ming wang', 'ziyu zhang', 'jiayang han', 'yin-long liu', 'rui feng', 'xiuyuan liang', 'zhen-hua ling', 'jia-hong yuan']\n\t- header: ['Decoding Speaker-Normalized Pitch from EEG for Mandarin Perception', 'Jiaxin Chen1,2, Yiming Wang1,2, Ziyu Zhang2, Jiayang Han2, Yin-Long Liu1,2, Rui Feng1,2, Xiuyuan', 'Liang2, Zhen-Hua Ling1,2, Jiahong Yuan1,2\u2217', '1National Engineering Research Center of Speech and Language Information Processing, University', 'of Science and Technology of China, Hefei, P. R. China', '2Interdisciplinary Research Center for Linguistic Sciences, University of Science and Technology of', 'China, Hefei, P. R. China']", "paper_id": "chen25e_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['\u015feymanur akti', 'tuan-nam nguyen', 'alexander waibel']\n\t- header: ['Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive', 'Voice Conversion', 'Seymanur Akti1, Tuan Nam Nguyen1, Alexander Waibel1,2', '1Interactive Systems Lab, Karlsruhe Institute for Technology, Germany', '2Carnegie Mellon University, USA']", "paper_id": "akti25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: [' mansi', 'anastasios lepipas', 'dominika c woszczyk', 'yiying guan', 'soteris demetriou']\n\t- header: ['Understanding Dementia Speech Alignment with Diffusion-Based Image', 'Generation', 'Mansi \u2217, Anastasios Lepipas \u2217, Dominika Woszczyk, Yiying Guan, Soteris Demetriou', 'Imperial College London, UK']", "paper_id": "mansi25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['jinxin ji', 'yiying hu', 'xiaohu yang', 'gang peng']\n\t- header: ['Acoustic Features of Mandarin Tone Production in Noise:  ', 'A Comparison Between Chinese Native Speakers and Korean L2 Learners ', 'Jinxin Ji 1,2; Yiying Hu 1; Xiaohu Yang 2*; Gang Peng 1* ', '1 Department of Chinese and Bilingual Studies, The Hong Kong Polytechnic University, Hong Kong SAR ', '2 Department of English, Tongji University, China ']", "paper_id": "ji25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['peidong wei', 'shiyu miao', 'lin li']\n\t- header: ['Abstract', 'Deep neural networks have been applied to audio spectro-', 'grams for respiratory sound classification, but it remains chal-', 'lenging to achieve satisfactory performance due to the scarcity', 'of available data. Moreover, domain mismatch may be intro-', 'duced into the trained models as a result of the respiratory sound', 'samples being collected from various electronic stethoscopes,', 'patient demographics, and recording environments. To tackle', 'this issue, we proposed a modified Masked Autoencoder (MAE)', 'model, named Disentangling Dual-Encoder MAE (DDE-MAE)', 'for respiratory sound classification. Two independent encoders', 'were designed to capture disease-related and disease-irrelevant', 'information separately, achieving feature disentanglement to re-', 'duce the domain mismatch. Our method achieves a competitive', 'performance on the ICBHI dataset.', 'Index Terms: respiratory sound classification, ICBHI, feature', 'disentanglement, masked autoencoder', '1. Introduction', 'Respiratory sound classification is an essential task in the early', 'detection and diagnosis of respiratory diseases. Accurate clas-', 'sification can assist healthcare professionals in identifying con-', 'ditions such as asthma, bronchitis, and pneumonia from respi-', 'ratory sounds[1]. However, several challenges arise due to the', 'variability in recording conditions.', 'Respiratory sound data are collected from different patients', 'using various stethoscopes in diverse environments. This vari-', 'ability introduces significant domain mismatch problems[2],', 'making it difficult for models to generalize across different', 'datasets[3][4]. Furthermore, in real-world scenarios, respira-', 'tory sound data are often from unseen domains, and obtaining', 'information about these specific domains is frequently imprac-', 'tical. This makes the challenge of domain adaptation even more', 'difficult to address.', 'Recently, numerous studies have attempted various meth-', 'ods to improve model performance. For instance, Audio Spec-', 'trogram Transformer with Patch-Mix and Contrastive Learning', '(AST + Patch-Mix CL)[5] employs a mix-based data augmenta-', 'tion method and establishes a corresponding contrastive learn-', 'ing approach to address the issue of data scarcity. The Multi-', 'View Spectrogram Transformer (MVST)[6] adopts an ensem-', 'ble approach that combines multiple models trained on different', 'views of the data to achieve performance enhancement. Bridg-', 'ing Text and Sound Modalities (BTS)[7] is a multimodal ap-', 'proach, integrating textual information, such as patient demo-', 'graphics (age, gender) and stethoscope recording conditions,', 'with audio data. Furthermore, some researchers have attempted', 'to address domain adaptation by utilizing the classification la-', 'bels of the stethoscope used during recording and incorporat-', 'ing these labels into domain adversarial[8] training methods[9].', 'Although it is helpful in improving performance, the approach', 'still heavily depends on the availability of labeled information,', 'which is often limited. For instance, the ICBHI dataset [10]', 'includes only four types of stethoscopes, and relying on these', \"limited labels restricts the model's ability to generalize to new,\", 'unseen environments or stethoscope types.', 'In this paper, we propose a novel self-supervised approach', 'that does not require label information of domain (e.g., types of', 'stethoscopes). The overall structure, the Disentangling Dual-', 'Encoder Masked Autoencoder[11] (DDE-MAE) is shown in', 'Fig. 1, which leverages the power of self-supervised learning', 'to disentangle disease-related features from disease-irrelevant', 'features. Hence, our model can achieve effective domain adap-', 'tation without the need for extensive domain labels.', 'Our DDE-MAE model employs two independent encoders.', 'The disease-related encoder captures features directly related', 'to respiratory diseases.', 'The disease-irrelevant encoder cap-', 'tures background and non-disease-related features by process-', 'ing both the original spectrogram and a time-shuffled version', 'of the spectrogram, using a Siamese loss to enforce feature', 'invariance to temporal changes. Additionally, To ensure that', 'the embeddings captured by the two encoders are independent,', 'we employ the variational Contrastive Log-ratio Upper Bound', '(vCLUB) algorithm [12] to estimate and minimize the mutual', 'information between the embeddings from the disease-related', 'encoder and the disease-irrelevant encoder. Our contributions', 'can be summarized as follows:', '\u2022 We introduce a dual-encoder architecture for respiratory', 'sound classification that disentangles disease-related and', 'disease-irrelevant information.', '\u2022 We propose a self-supervised learning approach that ad-', 'dresses domain adaptation without relying on domain infor-', 'mation.', '\u2022 We demonstrate the effectiveness of our method on the', 'ICBHI dataset, achieving a competitive performance and', 'highlighting its potential for real-world applications.', '2. Methodology', '2.1. Overview of Proposed DDE-MAE', 'Our proposed model, Disentangling Dual-Encoder MAE (DDE-', 'MAE), leverages the principles of the Masked Autoencoder', '(MAE) architecture to address the domain adaptation chal-', 'lenges in respiratory sound classification. The MAE architec-', 'ture typically consists of an encoder-decoder structure. The en-', 'coder processes the input spectrograms by masking a portion', 'of the input and learning to represent the unmasked parts effi-', 'ciently. The decoder reconstructs the masked parts from the en-', 'Disentangling', 'Dual-Encoder', 'Masked', 'Autoencoder', 'for', 'Respiratory', 'Sound', 'Classification', 'Peidong', 'Wei,', 'Shiyu', 'Miao,', 'Lin', 'Li*', ' School', 'of', 'Electronic', 'Science', 'and', 'Engineering,', 'Xiamen', 'University,', 'China', 'Interspeech 2025', '17-21 August 2025, Rotterdam, The Netherlands', '1013', '10.21437/Interspeech.2025-1209']", "paper_id": "wei25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['ahmed attia', 'dorottya demszky', 'jing liu', 'carol espy-wilson']\n\t- header: ['From Weak Labels to Strong Results: Utilizing 5,000 Hours of Noisy', 'Classroom Transcripts with Minimal Accurate Data', 'Ahmed Adel Attia1, Dorottya Demszky2, Jing Liu3, Carol Espy-Wilson1', '1Electrical and Computer Engineering, University of Maryland,', '2Graduate School of Education, Stanford University,', '3College of Education, University of Maryland,']", "paper_id": "attia25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['hawau toyin', 'rufael marew', 'humaid alblooshi', 'samar m. magdy', 'hanan aldarmaki']\n\t- header: ['ArVoice: A Multi-Speaker Dataset for Arabic Speech Synthesis', 'Hawau Olamide Toyin, Rufael Marew, Humaid Alblooshi, Samar M. Magdy, Hanan Aldarmaki', 'Mohamed Bin Zayed University of Artificial Intelligence, UAE']", "paper_id": "toyin25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['enes ugan', 'ngoc-quan pham', 'alexander waibel']\n\t- header: ['Weight Factorization and Centralization for Continual Learning', 'in Speech Recognition', 'Enes Yavuz Ugan1,\u2217, Ngoc-Quan Pham2,\u2217, Alexander Waibel1,2', '1Interactive Systems Lab, Karlsruhe Institut of Technology (KIT), Germany', '2InterACT, Carnegie Mellon University (CMU), USA']", "paper_id": "ugan25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['cathal \u00f3 faolain', 'andrew hines']\n\t- header: ['Attention Models and Auditory Transduction Features for Noise Robustness', 'Cathal \u00b4O Faol\u00b4ain1, Andrew Hines1', '1School of Computer Science, University College Dublin, Ireland']", "paper_id": "ofaolain25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['nagarathna ravi', 'thishyan raj t', 'ravi teja chaganti', 'vipul arora']\n\t- header: ['ASR Confidence Estimation using True Class Lexical Similarity Score', 'Nagarathna R1, Thishyan Raj T2, Ravi Teja Chaganti2, Vipul Arora2', '1Big Data Research and Supercomputing Division; AcSIR, CSIR-4PI, India', '2Department of Electrical Engineering, IIT Kanpur, India']", "paper_id": "ravi25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 430, "message": "no author alignment:\n\t- authors: ['zheng xin yong', 'vineel pratap', 'michael auli', 'jean maillard']\n\t- header: ['Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent', 'Robustness in Low-Resource ASR', 'Zheng-Xin Yong1,\u2217, Vineel Pratap2, Michael Auli\u2020, Jean Maillard2', '1Department of Computer Science, Brown University, United States', '2Meta FAIR, United States']", "paper_id": "yong25_interspeech", "error_step": "affiliations_extraction"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 419, "message": "moore25_interspeech doesn't have a PDF", "paper_id": "moore25_interspeech", "error_step": "pdf_loading"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 419, "message": "waibel25_interspeech doesn't have a PDF", "paper_id": "waibel25_interspeech", "error_step": "pdf_loading"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 419, "message": "espywilson25_interspeech doesn't have a PDF", "paper_id": "espywilson25_interspeech", "error_step": "pdf_loading"}
{"level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 419, "message": "holler25_interspeech doesn't have a PDF", "paper_id": "holler25_interspeech", "error_step": "pdf_loading"}
