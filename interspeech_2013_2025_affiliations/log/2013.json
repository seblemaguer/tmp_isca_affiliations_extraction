{"time": "2026-02-01 15:04:33,347", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "hermansky13_interspeech doesn't have a PDF", "paper_id": "hermansky13_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:04:33,347", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "munson13_interspeech doesn't have a PDF", "paper_id": "munson13_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:04:33,347", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "giraud13_interspeech doesn't have a PDF", "paper_id": "giraud13_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:04:33,347", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "clerc13_interspeech doesn't have a PDF", "paper_id": "clerc13_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:04:33,434", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['k. ramesh', 's. r. m. prasanna', 'd. govind']\n\t- header: ['Detection of Glottal Opening Instants using Hilbert Envelope', 'Ramesh K.1, S. R. M. Prasanna1 and D. Govind2', '1Department of Electronics and Electrical Engineering,', 'Indian Institute of Technology Guwahati, Guwahati 781039, India,', '2 CEN, Amrita University, Coimbatore']", "paper_id": "ramesh13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:33,591", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['j. a. gomez-garcia', 'juan ignacio godino-llorente', 'g. castellanos-dominguez']\n\t- header: ['Automatic gender recognition in normal and pathological speech', 'Gomez-Garcia J.A.1, Godino-Llorente J.I.1, Castellanos-Dominguez G.2', '1Universidad Politecnica de Madrid, Spain', '2Universidad Nacional de Colombia, Manizales, Colombia.']", "paper_id": "gomezgarcia13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:34,062", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['tatsuma ishihara', 'hirokazu kameoka', 'kota yoshizato', 'daisuke saito', 'shigeki sagayama']\n\t- header: ['Probabilistic speech F0 contour model incorporating statistical vocabulary', 'model of phrase-accent command sequence', 'Tatsuma Ishihara\u2020,Hirokazu Kameoka\u2020\u2021, Kota Yoshizato\u2020, Daisuke Saito\u2020, Shigeki Sagayama\u2020,', '\u2020Graduate School of Information Science and Technology, The University of Tokyo, Japan', '\u2021 NTT Communication Science Laboratories, NTT Corporation, Japan']", "paper_id": "ishihara13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:34,155", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['thi anh xuan tran', 'viet son nguyen', 'eric castelli', 'rene carre']\n\t- header: ['Production and perception of pseudo-V1CV2 outside the vowel triangle: Speech ', 'illusion effects ', 'Tran Thi Anh Xuan1, Viet Son Nguyen1, Eric Castelli1, Rene Carre2 ', '1 International Research Institute MICA, HUST - CNRS/UMI2954 - Grenoble INP, Hanoi ', 'University of Sciences and Technology, Hanoi, Vietnam ', '2 Laboratoire Dynamique du Langage - Universite de Lyon 2 - CNRS/URM5596 - Lyon, France ']", "paper_id": "tran13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:34,275", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['stefan hahn', 'patrick lehnen', 'simon wiesler', 'ralf schluter', 'hermann ney']\n\t- header: ['Improving LVCSR with Hidden Conditional Random Fields', 'for Grapheme-to-Phoneme Conversion', 'Stefan Hahn1,3,Patrick Lehnen1, Simon Wiesler1, Ralf Schluter1, Hermann Ney1,2', '1Human Language Technology and Pattern Recognition,', 'Computer Science Department, RWTH Aachen University, Aachen, Germany', '2Spoken Language Processing Group, LIMSI CNRS, Paris, France']", "paper_id": "hahn13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:34,506", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['david sheffield', 'michael anderson', 'yunsup lee', 'kurt keutzer']\n\t- header: ['Hardware/Software Codesign for Mobile Speech Recognition', 'David Sheffield,Michael Anderson,Yunsup Lee,Kurt Keutzer', 'Department of EECS, University of California, Berkeley, USA']", "paper_id": "sheffield13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:35,024", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['rui xia', 'yang liu']\n\t- header: ['Using Denoising Autoencoder for Emotion Recognition', 'Rui Xia,Yang Liu', '1Computer Science Department, The University of Texas at Dallas, Richardson, TX 75080']", "paper_id": "xia13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:35,052", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['vikas joshi', 'n. vishnu prasad', 's. umesh']\n\t- header: ['Modified Cepstral Mean Normalization - Transforming to utterance specific', 'non-zero mean', 'Vikas Joshi1,2,N. Vishnu Prasad1, S. Umesh1', '1 Department of Electrical Engineering, Indian Institute of Technology, Madras', '2 IBM India Research Labs, Bangalore']", "paper_id": "joshi13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:35,996", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['jose port\u00ealo', 'alberto abad', 'bhiksha raj', 'isabel trancoso']\n\t- header: ['Secure Binary Embeddings of Front-end Factor Analysis for Privacy', 'Preserving Speaker Verification', 'Jose Portelo12, Alberto Abad1, Bhiksha Raj3, Isabel Trancoso12', '1 INESC-ID Lisboa, Portugal; 2 Instituto Superior Tecnico, Lisboa, Portugal', '3 Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA']", "paper_id": "portelo13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,213", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['jin jin', 'joseph tepperman']\n\t- header: ['Jing Zheng1*, Joseph Tepperman2 ', '1 University of Colorado, Boulder ', '2 Rosetta Stone, USA  ', '* First author was an intern at Rosetta Stone at the time this work was completed. ']", "paper_id": "jin13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,332", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['haizhou li', 'john h.l. hansen', 'jean-francois bonastre', 's. marcel', 'john s. d. mason', 'eliathamby ambikairajah']\n\t- header: ['I4U submission to NIST SRE 2012:', 'A large-scale collaborative effort for noise-robust speaker verification', 'R. Saeidi1 , K. A. Lee2, T. Kinnunen3, T. Hasan4, B. Fauve5, P. -M. Bousquet6, E. Khoury7,', 'P. L. Sordo Martinez8, J. M. K. Kua9, C. H. You2, H. Sun2, A. Larcher2, P. Rajan3, V. Hautam\u00a8aki3,', 'C. Hanilci3, B. Braithwaite3, R. Gonzales-Hautam\u00a8aki3, S. O. Sadjadi4, G. Liu4, H. Boril4, N. Shokouhi4,', 'D. Matrouf6, L. El Shafey7, P. Mowlaee1, J. Epps9, T. Thiruvaran9, D. A. van Leeuwen1, B. Ma2, H. Li2,', 'J. H. L. Hansen4, J. -F. Bonastre6, S. Marcel7, J. Mason8, E. Ambikairajah9', '1Radboud University Nijmegen, The Netherlands, 2Institute for Infocomm Research, Singapore,', '3University of Eastern Finland, Finland, 4CRSS, University of Texas at Dallas, USA,', '5ValidSoft Ltd, London, UK, 6LIA, University of Avignon, France', '7Idiap Research Institute, Switzerland, 8Swansea University, UK,', '9University of New South Wales, Australia']", "paper_id": "li13f_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,437", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['e. gouv\u00eaa', 'a. moreno-daniel', 'a. reddy', 'r. chengalvarayan', 'd. thomson', 'a. ljolje']\n\t- header: ['The AT&T Speech API:', 'A Study on Practical Challenges for Customized Speech to Text Service', 'E. Gouvea, A. Moreno-Daniel, A. Reddy, R. Chengalvarayan, D. Thomson, A. Ljolje', 'AT&T Labs \u2013 Research, Bedminster NJ, USA']", "paper_id": "gouvea13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,528", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['ingrida balciunien\u0117']\n\t- header: ['Linguistic disfluency in narrative speech: Evidence from story-telling in 6-year ', 'olds ', 'Ingrida Balciunien\u0117 1 ', '1 Department of Lithuanian Language, Vytautas Magnus University, Kaunas, Lithuania ']", "paper_id": "balciuniene13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,626", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['zoltan tuske', 'ralf schluter', 'hermann ney']\n\t- header: ['Multilingual Hierarchical MRASTA Features for ASR', 'Zolt\u00b4an Tuskea, Ralf Schlutera, Hermann Neya,b', 'aHuman Language Technology and Pattern Recognition, Computer Science Department,', 'RWTH Aachen University, 52056 Aachen, Germany', 'bSpoken Language Processing Group, LIMSI CNRS, Paris, France']", "paper_id": "tuske13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,632", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['harry m. chang']\n\t- header: ['Heuristic Selection of Training Sentences from Historical TV Guide for Semi-', 'supervised LM Adaptation ', 'Harry M Chang ', 'AT&T Labs \u2013 Research, Austin, TX 78795, USA ']", "paper_id": "chang13c_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,755", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['adriana stan', 'o. watts', 'y. mamiya', 'm. giurgiu', 'robert a. j. clark', 'junichi yamagishi', 'simon king']\n\t- header: ['TUNDRA: A Multilingual Corpus of Found Data for TTS Research Created', 'with Light Supervision', 'A. Stan1, O. Watts2, Y. Mamiya2, M. Giurgiu1, R. A. J. Clark2, J. Yamagishi2,3, S. King2', '1Communications Department, Technical University of Cluj-Napoca, Romania', '2The Centre for Speech Technology Research, University of Edinburgh, UK', '3National Institute of Informatics, Japan']", "paper_id": "stan13b_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:36,838", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['agathe benoist-lucy', 'claire pillot-loiseau']\n\t- header: ['The Influence of language and speech task upon creaky voice use                ', 'among six young American women learning French  ', 'Benoist-lucy Agathe 1 Pillot-loiseau Claire 1 ', '1 Laboratoire de Phonetique et Phonologie, UMR 7018, CNRS/ Univ Sorbonne Nouvelle-Paris 3 ']", "paper_id": "benoistlucy13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:37,211", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['tsung-hsien wen', 'aaron heidel', 'hung-yi lee', 'yu tsao', 'lin-shan lee']\n\t- header: ['Recurrent Neural Network Based Language Model Personalization by Social', 'Network Crowdsourcing', 'Tsung-Hsien Wen1,Aaron Heidel1, Hung-yi Lee2, Yu Tsao2, and Lin-Shan Lee1', '1National Taiwan University,', '2Academic Sinica, Taipei, Taiwan']", "paper_id": "wen13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:37,802", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['m. a. tugtekin turan', 'engin erzin']\n\t- header: ['A New Statistical Excitation Mapping for Enhancement of Throat Microphone', 'Recordings', 'M.A. Tugtekin Turan and Engin Erzin', 'Multimedia, Vision and Graphics Laboratory,', 'College of Engineering, Koc University, Istanbul, Turkey']", "paper_id": "turan13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:37,971", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['joseph mariani', 'patrick paroubek', 'gil francopoulo', 'marine delaborde']\n\t- header: ['Rediscovering 25 Years of Discoveries in Spoken Language Processing: ', 'A preliminary ISCA Archive Analysis. ', 'J. Mariani1,2, P. Paroubek1, G. Francopoulo2,3, M. Delaborde1  ', '1LIMSI-CNRS, 2IMMI-CNRS, 3Tagmatica ']", "paper_id": "mariani13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:37,972", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "fujisaki13_interspeech doesn't have a PDF", "paper_id": "fujisaki13_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:04:37,972", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 402, "message": "moore13_interspeech doesn't have a PDF", "paper_id": "moore13_interspeech", "error_step": "pdf_loading"}
{"time": "2026-02-01 15:04:38,042", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['nguyen duc duy', 'masayuki suzuki', 'nobuaki minematsu', 'keikichi hirose']\n\t- header: ['Artificial bandwidth extension based on regularized piecewise linear mapping', 'with discriminative region weighting and long-span features', 'Duy Nguyen Duc, Masayuki Suzuki, Nobuaki Minematsu, Keikichi Hirose', 'The University of Tokyo, Tokyo, Japan', '1. Abstract', 'Artificial Bandwidth Extension (ABE) has been introduced to', 'improve perceived speech quality and intelligibility of narrow-', 'band telephone speech. Most of the existing algorithms divided', 'ABE into 2 sub-problems, namely extension of the excitation', 'signal and that of the spectral envelope. In this paper, we pro-', 'pose a new method for spectral envelope extension based on', 'REgularized piecewise linear mapping with DIscriminative re-', 'gion weighting And Long-span features (REDIAL). REDIAL is', 'a revised version of SPLICE, a well-known method for speech', 'enhancement. In REDIAL, however, discriminative model is', 'introduced for space division step of the original SPLICE.', 'The proposed REDIAL-based method approximates non-linear', 'transformation from narrowband features to their wideband', 'counterpart by a summation of piecewise linear transforma-', 'tions. The proposed method was compared with the widely used', 'GMM-based method, through objective and subjective evalua-', 'tions in both speaker-dependent and speaker-independent con-', 'ditions. Both evaluations showed that the proposed method sig-', 'nificantly outperforms the conventional GMM-based method.', 'Index Terms: Artificial Bandwidth Extension, REDIAL, spec-', 'tral envelope extension, objective and subjective evaluations', '2. Introduction', 'Although human ears are able to perceived sound at much', 'higher ferquencies than 8 kHz, and often more than 15 kHz,', 'traditional telephone networks were designed to limit the fre-', 'quency to a lower range, approximately below 3.4 kHz, in order', 'to conserve the bandwidth and increase the number of voice', 'streams transmittable by a transmission channel. This results', 'in degradation of perceptual speech quality of the narrowband', 'speech at receiving end. True wideband transmission is there-', 'fore desirable, but this requires a significant amount of cost and', 'time, since the whole transmission chain including terminals', 'and network elements need to be upgraded. This challenge can', 'be overcome with Artificial Bandwidth Extension (ABE) tech-', 'nique. ABE is a technique that tries to recover missing low and', 'high frequency components of the speech signal only from the', 'narrowband speech. By integrating ABE into terminals of the', 'telephone networks, we can easily realize wideband transmis-', 'sion without modifying the networks.', 'A number of techniques have been proposed over the years', 'for bandwidth extension of narrowband speech signals, includ-', 'ing methods based on codebook mapping [1] and statistical ap-', 'proaches [2, 3, 4]. Most of these ABE algorithms are based', 'on the source-filter model [5] of speech production whereby the', 'speech signal is regarded as output of the vocal tract filter which', 'takes excitation source signals as input. This model breaks the', 'problem down into two subtasks: one is to extend the spec-', 'tral envelope, and the other is to extend the excitation signal.', 'The extension of spectral envelope is typically considered as', 'the main problem of ABE since it had been shown that exten-', 'sion of the spectral envelope has a large effect on speech quality', 'of the reconstructed wideband speech [6].', 'It is known that the Gaussian Mixture Model (GMM) [7]', 'represents robustly the acoustic space of speech and was suc-', 'cessfully applied to the problem of spectral transformation, es-', 'pecially voice conversion [8]. Based on the successes in voice', 'conversion, in [4] an effective approach to the problem of ex-', 'tending the spectral envelope was proposed. In this approach,', 'the spectral envelope of wideband speech was estimated using', 'a GMM trained by parallel data of narrowband speech and its', 'corresponding wideband speech. This approach showed that', 'there was a large improvement in speech quality from the orig-', 'inal narrowband speech to the reconstructed wideband speech.', 'However, the gap between the reconstructed wideband and the', 'original wideband speech was still large.', 'Stereo-based Piecewise LInear Compensation for Environ-', 'ments (SPLICE) [9], in which non-linear transformation be-', 'tween two feature vectors is approximated by the summation', 'of piecewise linear transformations, is an effective and widely', 'used method in speech enhancement.', 'A revised version of', 'SPLICE, in which a discriminative model, long-span features', 'and regularization are introduced into SPLICE, was proposed', '[10, 11] and has been shown to outperform the original SPLICE.', 'This revised version was named REgularized piecewise linear', 'mapping with DIscriminative region weighting And Long-span', 'features (REDIAL). The aim of spectral envelope extension,', 'which is to make a transformation from spectral envelope of', 'narrowband speech to that of wideband speech, is very similar', 'to the scheme of REDIAL. This suggests that we can apply RE-', 'DIAL to the problem of spectral envelope extension as it is. In', 'this paper, we propose an approach to the problem of spectral', 'envelope extension based on REDIAL and describe its effec-', 'tiveness through objective and subjective evaluations.', 'This paper is organized as follow. Section. 3 describes the', 'conventional ABE method based on GMM. Section. 4 gives', 'a brief view of SPLICE and our proposed REDIAL-based', 'method. The general process of ABE is discussed in Section. 5.', 'Section. 6 describes experiments and results.', '3. GMM-based Bandwidth Extension [4, 8]', 'Let x = [x\u22a4', '1 , x\u22a4', '2 , ..., x\u22a4', 'N]\u22a4be the feature vectors charac-', 'terizing the narrowband and y = [y\u22a4', '1 , y\u22a4', '2 , ..., y\u22a4', 'N]\u22a4be the', 'feature vectors characterizing the wideband speech.', 'Xt =', '[x\u22a4', 't , \u2206x\u22a4', 't ]\u22a4and Yt = [y\u22a4', 't , \u2206y\u22a4', 't ]\u22a4define feature vectors', 'consisting of static and dynamic features at frame t of narrow-', 'band and wideband speech, respectively.', 'In the training step, we model the joint probability density', 'of the source and the target features by a GMM as follows:', 'P(Zt; \u03b8) =', 'M', '\u2211', 'm=1', '\u03c9mN(Zt; \u00b5(Z)', 'm , \u03a3(Z)', 'm )', '(1)', '\u03b8 defines a parameter set of GMM, which consisting of weights', '\u03c9m, mean vectors \u00b5(Z)', 'm', 'and covariance matrices \u03a3(Z)', 'm . M is', 'the total number of mixture components of GMM, and m is', 'Copyright \u00a9 2013 ISCA', '25-29 August 2013, Lyon, France', 'INTERSPEECH 2013', '3453', '10.21437/Interspeech.2013-756']", "paper_id": "duy13_interspeech", "error_step": "affiliations_extraction"}
{"time": "2026-02-01 15:04:38,081", "level": "ERROR", "filename": "extract_affiliations_manually.py", "line_number": 413, "message": "no author alignment:\n\t- authors: ['laurianne georgeton', 'nicolas audibert']\n\t- header: ['Is protrusion of French rounded vowels affected by prosodic positions? ', 'Georgeton Laurianne1, Audibert Nicolas1 ', '1 Laboratoire de phonetique et de phonologie, UMR 7018 CNRS/Univ. Sorbonne Nouvelle Paris 3 ']", "paper_id": "georgeton13_interspeech", "error_step": "affiliations_extraction"}
